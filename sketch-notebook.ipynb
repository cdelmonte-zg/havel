{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6ac7ffd-01d8-49e7-9728-88753c893d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# pip install datasketch[redis]\n",
    "# pip install elasticsearch==7.10.0\n",
    "# pip install neo4j\n",
    "# pip install pyyaml\n",
    "# pip install deepdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc93d049-4578-483c-80b6-e5fd605d1596",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "500 Server Error: Server Error for url: http://localhost:8998/sessions/36/statements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-3990bab0be7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mLivySession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLIVY_URL\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'print(\"foo\")'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'files_df'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\livy\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, code)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mto\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \"\"\"\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mecho\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\livy\\session.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, code)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mOutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m         \u001b[0mstatement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_statement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m         \u001b[0mintervals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolling_intervals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\livy\\client.py\u001b[0m in \u001b[0;36mcreate_statement\u001b[1;34m(self, session_id, code, kind)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"kind\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m         response = self._client.post(\n\u001b[0m\u001b[0;32m    291\u001b[0m             \u001b[1;34mf\"/sessions/{session_id}/statements\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\livy\\client.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, endpoint, data)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"POST\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\livy\\client.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, endpoint, data, params)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         )\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 943\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: 500 Server Error: Server Error for url: http://localhost:8998/sessions/36/statements"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "\n",
    "from livy import LivySession\n",
    "from textwrap import dedent\n",
    "\n",
    "LIVY_URL = 'http://localhost:8998'\n",
    "\n",
    "with LivySession.create(LIVY_URL) as session:\n",
    "    session.run('print(\"foo\")')\n",
    "   \n",
    "    session.upload('files_df', files_df)\n",
    "\n",
    "    session.run(dedent(\"\"\"\n",
    "        print(files_df)\n",
    "    \"\"\"))\n",
    "    # top_ten_pandas.append(session.read('df'))\n",
    "            file = filename.first().getString(0)\n",
    "            df = spark.read.csv('/sample_data/')\n",
    "            top_ten = df.limit(10)\n",
    "top_ten_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90e532c6-c249-4cf5-be66-2c693158afbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tLast name\tFirst name\tSSN\tTest1\tTest2\tTest3\tTest4\tFinal\tGrade\n",
      "\tAlfalfa\tAloysius\t123-45-6789\t40\t90\t100\t83\t49\tD-\n",
      "\tAlfred\tUniversity\t123-12-1234\t41\t97\t96\t97\t48\tD+\n",
      "\tGerty\tGramma\t567-89-0123\t41\t80\t60\t40\t44\tC\n",
      "\tAndroid\tElectric\t087-65-4321\t42\t23\t36\t45\t47\tB-\n",
      "\tBumpkin\tFred\t456-78-9012\t43\t78\t88\t77\t45\tA-\n",
      "\tRubble\tBetty\t234-56-7890\t44\t90\t80\t90\t46\tC-\n",
      "\tNoshow\tCecil\t345-67-8901\t45\t11\t-1\t4\t43\tF\n",
      "\tBuff\tBif\t632-79-9939\t46\t20\t30\t40\t50\tB+\n",
      "\tAirpump\tAndrew\t223-45-6789\t49\t1\t90\t100\t83\tA\n",
      "\tBackus\tJim\t143-12-1234\t48\t1\t97\t96\t97\tA+\n",
      "\tCarnivore\tArt\t565-89-0123\t44\t1\t80\t60\t40\tD+\n",
      "\tDandy\tJim\t087-75-4321\t47\t1\t23\t36\t45\tC+\n",
      "\tElephant\tIma\t456-71-9012\t45\t1\t78\t88\t77\tB-\n",
      "\tFranklin\tBenny\t234-56-2890\t50\t1\t90\t80\t90\tB-\n",
      "\tGeorge\tBoy\t345-67-3901\t40\t1\t11\t-1\t4\tB\n",
      "\tHeffalump\tHarvey\t632-79-9439\t30\t1\t20\t30\t40\tC\n",
      "\n",
      "\n",
      "_mapping response: {\n",
      "    \"X-TIKA:Parsed-By\": [\n",
      "        \"org.apache.tika.parser.DefaultParser\",\n",
      "        \"org.apache.tika.parser.csv.TextAndCSVParser\"\n",
      "    ],\n",
      "    \"X-TIKA:Parsed-By-Full-Set\": [\n",
      "        \"org.apache.tika.parser.DefaultParser\",\n",
      "        \"org.apache.tika.parser.csv.TextAndCSVParser\"\n",
      "    ],\n",
      "    \"X-TIKA:content_handler\": \"ToTextContentHandler\",\n",
      "    \"Content-Encoding\": \"ISO-8859-1\",\n",
      "    \"X-TIKA:parse_time_millis\": \"4\",\n",
      "    \"X-TIKA:embedded_depth\": \"0\",\n",
      "    \"resourceName\": \"b'webhdfs-v1-grades.csv'\",\n",
      "    \"csv:delimiter\": \"comma\",\n",
      "    \"Content-Length\": \"747\",\n",
      "    \"Content-Type\": \"text/csv; charset=ISO-8859-1; delimiter=comma\"\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "\n",
    "# import parser object from tike\n",
    "from tika import parser  \n",
    "\n",
    "import tika\n",
    "  \n",
    "url = 'https://aclanthology.org/2020.acl-main.577.pdf'\n",
    "url = 'http://127.0.0.1:9864/webhdfs/v1/grades.csv?op=OPEN&namenoderpcaddress=master:9000&offset=0'\n",
    "pdfFile = parser.from_file(url)\n",
    "\n",
    "print(pdfFile['content'])\n",
    "\n",
    "print (\"_mapping response:\", json.dumps(pdfFile['metadata'], indent=4), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e87eca-bb6e-4dc8-9d8f-98d67a1b4a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventureworks-for-postgres\n",
      "+--------------------+------+\n",
      "|            Filename|Length|\n",
      "+--------------------+------+\n",
      "|adventureworks-fo...|     0|\n",
      "+--------------------+------+"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o files_df\n",
    "\n",
    "import ntpath\n",
    "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType, DecimalType\n",
    "\n",
    "hadoop = sc._jvm.org.apache.hadoop\n",
    "\n",
    "fs = hadoop.fs.FileSystem\n",
    "conf = hadoop.conf.Configuration() \n",
    "path = hadoop.fs.Path('/sample_data/')\n",
    "\n",
    "files = []\n",
    "for f in fs.get(conf).listStatus(path):\n",
    "    filename = ntpath.basename(str(f.getPath()))\n",
    "    print(filename)\n",
    "    files.append((filename, f.getLen()))\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('Filename', StringType(), True),\n",
    "    StructField('Length', StringType(), True)\n",
    "])\n",
    "\n",
    "# Convert list to RDD\n",
    "rdd = spark.sparkContext.parallelize(files)\n",
    "\n",
    "# Create data frame\n",
    "files_df = spark.createDataFrame(rdd,schema)\n",
    "files_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97624a33-e541-4925-b4d6-3c5f1cb4fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "\n",
    "from datetime import datetime\n",
    "from datasketch import MinHash\n",
    "from datasketch import MinHashLSH\n",
    "from datasketch import LeanMinHash\n",
    "from elasticsearch import Elasticsearch\n",
    "from redis import StrictRedis\n",
    "import redis\n",
    "import json\n",
    "import pickle\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from dataclasses import dataclass\n",
    "from deepdiff import DeepDiff\n",
    "from pprint import pprint\n",
    "from typing import Dict, Any\n",
    "import hashlib\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "config = []\n",
    "config_data = []\n",
    "try:\n",
    "    with open('havel-config.yaml', 'r') as f:\n",
    "        config = yaml.load(f, Loader=SafeLoader)\n",
    "        for source in config['sources']:\n",
    "            for schema in config['sources'][source]:\n",
    "                url = config['sources'][source][schema]['url']\n",
    "                datasets = config['sources'][source][schema]['datasets']\n",
    "                for dataset in datasets:\n",
    "                    dataframe = 0\n",
    "                    config_data.append((source, schema, dataset, url, dataframe))\n",
    "\n",
    "except yaml.YAMLError:\n",
    "    print(\"Error in configuration file\")\n",
    "\n",
    "config_df = pd.DataFrame (config_data, columns = ['source', 'schema', 'dataset', 'url', 'dataframe'])\n",
    "date = '2022-11-20'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93dbb6ed-2365-4ede-8eeb-3f1d5a8ebce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>46</td><td>application_1669190981900_0008</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://master:8088/proxy/application_1669190981900_0008/\">Link</a></td><td><a target=\"_blank\" href=\"http://worker1:8042/node/containerlogs/container_1669190981900_0008_01_000001/root\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'config_df' as 'data' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i config_df -t df -n data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf3e862-9505-4402-9a15-4f6d2d7434b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully passed 'date' as 'date' to Spark kernel"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i date -t str -n date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd69e99a-02e0-49f1-ba8b-28d47a1e6287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "def read_data(i, date):\n",
    "    abs_path = 'sample_data'\n",
    "    source = data.rdd.map(lambda r: r.source).collect()[i]\n",
    "    schema = data.rdd.map(lambda r: r.schema).collect()[i]\n",
    "    dataset = data.rdd.map(lambda r: r.dataset).collect()[i]\n",
    "    globals()[f\"df_{i}\"] = spark.read.format(\"csv\").option(\"header\", \"true\").load(f\"/{abs_path}/{source}/{schema}/{date}/{dataset}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f605ec4-9aa9-4f5a-9e1c-fa5a90fd262e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_0\n",
    "\n",
    "read_data(0, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e29a3f5-3068-402b-af3f-b45e5574014d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_1\n",
    "\n",
    "read_data(1, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e91831d-8e70-4de5-953f-37ca894b4d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_2\n",
    "\n",
    "read_data(2, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d84d60f4-977a-45b6-84e9-c7bcaf711581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_3\n",
    "\n",
    "read_data(3, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fcce3c-d8df-4596-92d3-deb9be43f116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_4\n",
    "\n",
    "read_data(4, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d6db5d-0d79-4219-962d-304bceef6186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_5\n",
    "\n",
    "read_data(5, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1553640-6217-407a-be71-f7954828c7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_6\n",
    "\n",
    "read_data(6, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc511a88-a882-40be-be30-0661282e05fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_7\n",
    "\n",
    "read_data(7, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f719252-3d46-4459-96b6-3de272aaa82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_8\n",
    "\n",
    "read_data(8, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ae207b4-d46f-492c-bacc-a8001731d533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_9\n",
    "\n",
    "read_data(9, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c84622dd-2e75-4cca-b50a-fe45f2154c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_10\n",
    "\n",
    "read_data(10, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e13fd336-0d3d-4df8-8d25-550f682b550e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_11\n",
    "\n",
    "read_data(11, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b2a14c2-2088-4a33-92c1-0a8e98f530d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_12\n",
    "\n",
    "read_data(12, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc1d47f-96a2-43ba-82a3-08c900c5c321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_13\n",
    "\n",
    "read_data(13, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "603c5593-5772-4fe4-a38e-f58ea312f0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_14\n",
    "\n",
    "read_data(14, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea0f723c-7c39-4091-b120-ce738fa9a132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_15\n",
    "\n",
    "read_data(15, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dd3d97c-da87-4ff0-b407-19caa58085a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o df_16\n",
    "\n",
    "df_16 = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/sample_data/adventureworks-for-postgres/person/2022-11-23/address.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79c2d843-acdd-4a0e-a639-de0fc4f730bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2720ac46309048ad8ad82393dec750e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='Type:'), Button(description='Table', layout=Layout(width='70px'), st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acb3b3037954d62a214033647fd3c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%local \n",
    "df_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "394f993a-598b-4dd0-9921-0c6343bc9d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local \n",
    "df_0 = df_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbb6765d-8925-4009-bd55-b7eade095541",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "\n",
    "def add_df_to_data(data, df, i):\n",
    "    row = list(data[i])\n",
    "    row[4] = df\n",
    "    data[i] = tuple(row)\n",
    "\n",
    "for i in range(0, len(config_data)):\n",
    "    add_df_to_data(config_data, globals()[f\"df_{i}\"], i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63518b48-8748-4113-a1d1-998bc0b39fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e0e22fefe445038693bfb7d666f12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='Type:'), Button(description='Table', layout=Layout(width='70px'), st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e4650bb9894c368fc2bd883b8127ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%local\n",
    "config_data[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f3c34f2-2849-4f06-806a-b6cf03390161",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "\n",
    "\n",
    "def calc_idx_content(data):\n",
    "    return \"%s-%s-%s-%s\"%(data['source'].replace(' ', '_'), data['schema'].replace(' ', '_'), data['dataset'].replace(' ', '_'), data['attribute'].replace(' ', '_'))\n",
    "\n",
    "def calc_idx_signature(data):\n",
    "    return \"%s-%s-%s\"%(data['source'].replace(' ', '_'), data['schema'].replace(' ', '_'), data['dataset'].replace(' ', '_'))\n",
    "\n",
    "def get_df_data_types_as_dict(df):\n",
    "    return df.dtypes.apply(lambda x: x.name).to_dict()\n",
    "\n",
    "def serialize_dict_data_types(data_types):\n",
    "    return json.dumps(data_types, sort_keys=True)\n",
    "\n",
    "def deserialize_dict_data_types(ser_df_data_types):\n",
    "    return  json.loads(ser_df_data_types)\n",
    "\n",
    "def compare_dicts(dict_a, dict_b):\n",
    "    return DeepDiff(dict_a, dict_b)\n",
    "\n",
    "\n",
    "def dict_hash(dictionary: Dict[str, Any]) -> str:\n",
    "    \"\"\"MD5 hash of a dictionary.\"\"\"\n",
    "    dhash = hashlib.md5()\n",
    "    encoded = json.dumps(dictionary, sort_keys=True).encode()\n",
    "    dhash.update(encoded)\n",
    "    return dhash.hexdigest()\n",
    "\n",
    "\n",
    "def calc_profile_content(source, schema, dataset, df):\n",
    "    doc = []\n",
    "    min_hashes = []\n",
    "    \n",
    "    for c_n in df.columns:\n",
    "        m = MinHash(num_perm=128)\n",
    "        s = df[c_n]\n",
    "        dtype = str(s.dtype)\n",
    "        crd = s.nunique()\n",
    "        keywords = []\n",
    "        \n",
    "        for v in s:\n",
    "            if dtype == 'int64': \n",
    "                v = str(v)\n",
    "                m.update(v.encode('utf8'))\n",
    "            elif dtype == 'datetime64[ns]': \n",
    "                v = v.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "                m.update(v.encode('utf8'))\n",
    "            elif (isinstance(v, float)):\n",
    "                 m.update((str(v)).encode('utf8'))\n",
    "            else:\n",
    "                m.update(v.encode('utf8'))\n",
    "                keywords.append(v)\n",
    "        \n",
    "        data = {}\n",
    "        data['source'] = source\n",
    "        data['schema'] = schema\n",
    "        data['dataset'] = dataset\n",
    "        data['attribute'] = c_n\n",
    "        data['data_type'] = dtype\n",
    "        data['timestamp'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        data['size'] = s.size\n",
    "        data['cardinality'] = crd\n",
    "        data['uniqueness'] = crd / s.size     \n",
    "        data['min_hash'] =  m.hashvalues\n",
    "        data['min_hash_seed'] = m.seed\n",
    "        data['keywords'] = ' '.join(keywords)\n",
    "        \n",
    "        min_hashes.append((calc_idx_content(data), m))\n",
    "        doc.append(data)\n",
    "\n",
    "    return doc, min_hashes\n",
    "\n",
    "\n",
    "def calc_profile_signature(source, schema, dataset, df):\n",
    "    doc = []\n",
    "    min_hashes = []\n",
    "    keywords = []\n",
    "       \n",
    "    m = MinHash(num_perm=128)\n",
    "    for c in df.columns:\n",
    "        m.update(c.encode('utf8'))\n",
    "        keywords.append(c)\n",
    "        \n",
    "    data = {}\n",
    "    data['source'] = source\n",
    "    data['schema'] = schema\n",
    "    data['dataset'] = dataset\n",
    "    data['timestamp'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    data['min_hash'] =  m.hashvalues\n",
    "    data['min_hash_seed'] = m.seed\n",
    "    data['data_types'] = serialize_dict_data_types(get_df_data_types_as_dict(df))\n",
    "    data['keywords'] = ' '.join(keywords)\n",
    "    \n",
    "    min_hashes.append((calc_idx_signature(data), m))\n",
    "    \n",
    "    data['version'] = calc_version(calc_idx_signature(data), get_df_data_types_as_dict(df))\n",
    "    \n",
    "    doc.append(data)\n",
    "    \n",
    "    return doc, min_hashes\n",
    "\n",
    "\n",
    "\n",
    "def calc_version(k, d):\n",
    "    h = dict_hash(d)\n",
    "    v = version_cache.get(k)\n",
    "    version = 0\n",
    "    \n",
    "    print(v)\n",
    "    if v:\n",
    "        ser = json.loads(v)\n",
    "        print(ser)\n",
    "        print(k)\n",
    "        version = int(ser['version'])\n",
    "        if ser['hash'] != h:\n",
    "            version = version + 1\n",
    "            print('Version incremented for key: %s' % k)\\\n",
    "    \n",
    "    nd = {\n",
    "        'hash': h,\n",
    "        'version': version\n",
    "    }\n",
    "    \n",
    "    version_cache.set(k, json.dumps(nd))\n",
    "        \n",
    "    return version\n",
    "\n",
    "\n",
    "\n",
    "def insert_min_hashes(min_hashes, lsh_list):\n",
    "    for threshold, lsh in lsh_list.items():\n",
    "        with lsh.insertion_session() as session:\n",
    "            for key, minhash in min_hashes:\n",
    "                label = key\n",
    "                if debug: print(label)\n",
    "                if debug: print(minhash)\n",
    "                try:\n",
    "                    lsh.remove(label)\n",
    "                except:\n",
    "                    print(\"Key %s doesn't exist.\"%label) \n",
    "                session.insert(label, minhash)\n",
    "\n",
    "\n",
    "                \n",
    "def upsert(env, index, func_calc_idx, doc, v=True):\n",
    "    for data in doc:\n",
    "        res = es.index(index=index, id=func_calc_idx(data), body=data)\n",
    "\n",
    "    es.indices.refresh(index=index)\n",
    "    \n",
    "    if v is True:\n",
    "        res = es.search(size=es_res_max_size, index=index, body={\"query\": {\"match_all\": {}}})\n",
    "        if debug: print(\"Got %d Hits.\" % res['hits']['total']['value'])\n",
    "\n",
    "        \n",
    "def clear_cache_ns(ns):\n",
    "    \"\"\"\n",
    "    Clears a namespace in redis cache.\n",
    "    This may be very time consuming.\n",
    "    :param ns: str, namespace i.e your:prefix*\n",
    "    :return: int, num cleared keys\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    pipe = cache.pipeline()\n",
    "    for key in cache.scan_iter(ns):\n",
    "        pipe.delete(key)\n",
    "        count += 1\n",
    "    pipe.execute()\n",
    "    return count\n",
    "\n",
    "\n",
    "def clear_es(env):\n",
    "    # delete all\n",
    "    indices = [index_content[env], index_signature[env]]\n",
    "        \n",
    "    try:\n",
    "        es.delete_by_query(index=indices, body={\"query\": {\"match_all\": {}}})\n",
    "        es.indices.delete(index=indices, ignore=[400, 404])\n",
    "    except Exception as e:\n",
    "        print(\"Delete Index: %s\", e)\n",
    "\n",
    "def create_es_schema_signature(env):\n",
    "    schema = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"source\": {\n",
    "                    \"type\": \"text\" # formerly \"string\"\n",
    "                },\n",
    "                \"schema\": {\n",
    "                    \"type\": \"text\" # formerly \"string\"\n",
    "                },\n",
    "                \"dataset\": {\n",
    "                    \"type\": \"text\" # formerly \"string\"\n",
    "                },\n",
    "                \"timestamp\": {\n",
    "                    \"type\": \"date\",\n",
    "                    \"format\": \"yyyy-MM-dd HH:mm:ss.SSSSSS\"\n",
    "                    # data format for Python's datetime.now() method\n",
    "                },\n",
    "                \"min_hash\": {\n",
    "                    \"ignore_malformed\": \"true\",\n",
    "                    \"type\": \"integer\"\n",
    "                },\n",
    "                \"min_hash_seed\": {\n",
    "                    \"type\": \"integer\"\n",
    "                },\n",
    "                \"data_types\": {\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"version\": {\n",
    "                    \"type\": \"integer\"\n",
    "                },\n",
    "                \"keywords\": {\n",
    "                    \"type\": \"text\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    resp = es.indices.create(\n",
    "        index = index_signature[env],\n",
    "        body = schema\n",
    "    )\n",
    "    \n",
    "    if debug: print (\"_mapping response:\", json.dumps(resp, indent=4), \"\\n\")\n",
    "\n",
    "    \n",
    "def create_es_schema_content(env):\n",
    "    schema = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"source\": {\n",
    "                    \"type\": \"text\" # formerly \"string\"\n",
    "                },\n",
    "                \"schema\": {\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"dataset\": {\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"attribute\": {\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"data_type\": {\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                 \"timestamp\": {\n",
    "                    \"type\": \"date\",\n",
    "                    \"format\": \"yyyy-MM-dd HH:mm:ss.SSSSSS\"\n",
    "                    # data format for Python's datetime.now() method\n",
    "                },\n",
    "                \"size\": {\n",
    "                    \"type\": \"integer\"\n",
    "                },\n",
    "                \"cardinality\": {\n",
    "                    \"type\": \"float\"\n",
    "                },\n",
    "                \"uniqueness\": {\n",
    "                    \"type\": \"float\"\n",
    "                },\n",
    "                \"min_hash\": {\n",
    "                    \"ignore_malformed\": \"true\",\n",
    "                    \"type\": \"integer\"\n",
    "                },\n",
    "                \"min_hash_seed\": {\n",
    "                    \"type\": \"integer\"\n",
    "                },\n",
    "                \"keywords\": {\n",
    "                    \"type\": \"text\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    resp = es.indices.create(\n",
    "        index = index_content[env],\n",
    "        body = schema\n",
    "    )\n",
    "    \n",
    "    if debug: print (\"_mapping response:\", json.dumps(resp, indent=4), \"\\n\")\n",
    "\n",
    "    \n",
    "def create_profiles_content(source, schema, dataset, df, env, lsh_list):\n",
    "    doc, min_hashes = calc_profile_content(source, schema, dataset, df)\n",
    "    insert_min_hashes(min_hashes, lsh_list)\n",
    "    index = index_content[env]\n",
    "    \n",
    "    try:\n",
    "        upsert(env, index, calc_idx_content, doc)\n",
    "    except Exception as e:\n",
    "        print(\"something didn't work\", doc, \"\\n\", str(e))\n",
    "        \n",
    "\n",
    "def create_profiles_signature(source, schema, dataset, df, env, lsh_list):\n",
    "    doc, min_hashes = calc_profile_signature(source, schema, dataset, df)\n",
    "    insert_min_hashes(min_hashes, lsh_list)\n",
    "    index = index_signature[env]\n",
    "    \n",
    "    try:\n",
    "        upsert(env, index, calc_idx_signature, doc)\n",
    "    except Exception as e:\n",
    "        print(\"something didn't work\", doc, \"\\n\", str(e))\n",
    "\n",
    "\n",
    "def get_nodes_and_edges(env, index, lsh_list):\n",
    "    res = es.search(size=es_res_max_size, index=index, body={\"query\": {\"match_all\": {}}})\n",
    "    if debug: print(\"Got %d Hits.\" % res['hits']['total']['value'])\n",
    "\n",
    "    relations = []\n",
    "\n",
    "    for hit in res['hits']['hits']:\n",
    "        min_hash_hashes = np.array(hit['_source'][\"min_hash\"],  dtype=np.int64)\n",
    "        min_hash_seed = hit['_source'][\"min_hash_seed\"]\n",
    "\n",
    "        mt = MinHash(num_perm=128)\n",
    "        mt.hashvalues = min_hash_hashes\n",
    "        mt.seed = min_hash_seed\n",
    "        \n",
    "        for threshold, lsh in lsh_list.items():\n",
    "            bucket = lsh.query(mt)\n",
    "            relations.append((hit['_id'], bucket, str(threshold)))\n",
    "    return (res['hits']['hits'], relations)\n",
    "\n",
    "\n",
    "def search_dataset_for_topic(index, topic):\n",
    "    resp = es.search(\n",
    "        index= index,\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"keywords\": topic\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    res = []\n",
    "    for r in resp['hits']['hits']:\n",
    "        res.append({\n",
    "            'id': r['_id'], \n",
    "            'score': r['_score'],\n",
    "            'source': r['_source']['source'], \n",
    "            'schema': r['_source']['schema'], \n",
    "            'dataset': r['_source']['dataset'], \n",
    "            'attribute': r['_source']['attribute']})\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b0d75a4-1671-46ac-a5ef-77acce27d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from textwrap import dedent\n",
    "\n",
    "class GraphStorage:\n",
    "\n",
    "    def __init__(self, uri, user, password, env, debug):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        self.env = env\n",
    "        self.debug = debug\n",
    "        \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def insert_column_node(self, idx_col, idx_tab, data):\n",
    "        with self.driver.session() as session:\n",
    "            res1 = session.execute_write(self._create_column_node, idx_col, data, self.env)\n",
    "            res2 = session.execute_write(self._create_column_table_relation, idx_col, idx_tab, self.env)\n",
    "            if self.debug: print(res1)\n",
    "            if self.debug: print(res2)\n",
    "    \n",
    "    def insert_table_node(self, idx, data):\n",
    "        with self.driver.session() as session:\n",
    "            res = session.execute_write(self._create_table_node, idx, data, self.env)\n",
    "            if self.debug: print(res)\n",
    "            \n",
    "    def add_column_column_relation(self, idx_a, idx_b, threshold):\n",
    "        with self.driver.session() as session:\n",
    "            res = session.execute_write(self._create_column_column_relation, idx_a, idx_b, threshold, self.env)\n",
    "            if self.debug: print(res)\n",
    "    \n",
    "    def add_table_table_relation(self, idx_a, idx_b, threshold):\n",
    "        with self.driver.session() as session:\n",
    "            res = session.execute_write(self._create_table_table_relation, idx_a, idx_b, threshold, self.env)\n",
    "            if self.debug: print(res)\n",
    "            \n",
    "    def remove_self_relations(self):\n",
    "        with self.driver.session() as session:\n",
    "            res = session.execute_write(self._delete_self_relations, self.env)\n",
    "            if self.debug: print(res)     \n",
    "    \n",
    "    def delete_all(self):\n",
    "        with self.driver.session() as session:\n",
    "            res = session.execute_write(self._delete_all, self.env)\n",
    "            if self.debug: print(res)\n",
    "    \n",
    "    \n",
    "    def find_related_tables_by_signature_to_2_grade(self, dataset, weight, dastart, daend):\n",
    "        with self.driver.session() as session:\n",
    "            res = session.execute_read(self._fetch_related_tables_by_signature_to_2_grade, dataset, weight, dastart, daend, self.env)\n",
    "            if self.debug: print(res)\n",
    "\n",
    "            return res\n",
    "        \n",
    "    def find_related_tables_by_content_to_1_grad(self, attribute, weight, dastart, daend):\n",
    "        with self.driver.session() as session:\n",
    "            res = session.execute_read(self._fetch_related_tables_by_content_to_1_grade, attribute, weight, dastart, daend, self.env)\n",
    "            if self.debug: print(res)\n",
    "\n",
    "            return res    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_column_node(tx, idx, data, env):\n",
    "        result = tx.run(\"MERGE (a:Column {idx: $idx, source: $source, schema: $schema, dataset: $dataset, version: $version, env: $env, \"\n",
    "                        \"attribute: $attribute, data_type: $data_type, uniqueness: $uniqueness}) \"\n",
    "                        \"ON CREATE SET a.createdAt = timestamp(), a.updatetAt = timestamp() \"\n",
    "                        \"ON MATCH SET a.updatetAt = timestamp() \"\n",
    "                        \"RETURN a.name + ' created as node ' + id(a) \",\n",
    "                        source=data['source'], schema=data['schema'], dataset=data['dataset'], version=1, timestamp=data['timestamp'],\n",
    "                        attribute=data['attribute'],  data_type=data['data_type'], cardinality=data['cardinality'],  uniqueness=data['uniqueness'], \n",
    "                        env=env, idx=idx)\n",
    "        \n",
    "        return result.single()[0]\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_table_node(tx, idx, data, env):\n",
    "        result = tx.run(\"MERGE (a:Table{idx: $idx, source: $source, schema: $schema, dataset: $dataset, version: $version, env: $env}) \"\n",
    "                        \"ON CREATE SET a.createdAt = timestamp(), a.updatetAt = timestamp() \"\n",
    "                        \"ON MATCH SET a.updatetAt = timestamp() \"\n",
    "                        \"RETURN a.name + ' created as node ' + id(a) \", \n",
    "                        source=data['source'], schema=data['schema'], dataset=data['dataset'], version=data['version'], timestamp=data['timestamp'], \n",
    "                        env=env, idx=idx)\n",
    "        return result.single()[0]\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_table_table_relation(tx, idx_a, idx_b, weight, env):\n",
    "        result = tx.run(\"MATCH (a:Table {idx: $idx_a, env: $env}), (b:Table {idx: $idx_b, env: $env}) \"\n",
    "                        \"MERGE (a)-[r:IS_SIMILAR_TO {weight: $weight}]-(b) \"\n",
    "                        \"ON CREATE SET r.createdAt = timestamp() , r.updatetAt = timestamp()\"\n",
    "                        \"ON MATCH SET r.updatetAt = timestamp() \"\n",
    "                        \"RETURN 'relation ' + type(r) + ' created between ' + a.dataset + ' and ' + b.dataset\",\n",
    "                        idx_a=idx_a, idx_b=idx_b, weight=weight, env=env)\n",
    "        \n",
    "        entire_result = []\n",
    "        for record in result:\n",
    "            entire_result.append(record[0])\n",
    "            \n",
    "        return entire_result\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_column_table_relation(tx, idx_col, idx_tab, env):\n",
    "        result = tx.run(\"MATCH (t:Table {idx: $idx_tab, env: $env}) \"\n",
    "                        \"WITH max(t.version) AS maximum \"\n",
    "                        \"MATCH (c:Column {idx: $idx_col, env: $env}), (t:Table {idx: $idx_tab, env: $env}) \"\n",
    "                        \"WHERE t.version = maximum \"\n",
    "                        \"MERGE (c)-[r:IS_ATTRIBUTE_OF {weight: '1.0'}]->(t) \"\n",
    "                        \"ON CREATE SET r.createdAt = timestamp(), r.updatetAt = timestamp() \"\n",
    "                        \"ON MATCH SET r.updatetAt = timestamp() \"\n",
    "                        \"RETURN 'relation ' + type(r) + ' created between ' + c.attribute + ' and ' + t.dataset\", \n",
    "                        idx_tab=idx_tab, idx_col=idx_col, env=env)\n",
    "        \n",
    "        entire_result = []\n",
    "        for record in result:\n",
    "            entire_result.append(record[0])\n",
    "            \n",
    "        return entire_result\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_column_column_relation(tx, idx_a, idx_b, weight, env):\n",
    "        result = tx.run(\"MATCH (a:Column {idx: $idx_a, env: $env}), (b:Column {idx: $idx_b, env: $env}) \"\n",
    "                        \"MERGE (a)-[r:IS_SIMILAR_TO {weight: $weight}]-(b) \"\n",
    "                        \"ON CREATE SET r.createdAt = timestamp(), r.updatetAt = timestamp() \"\n",
    "                        \"ON MATCH SET r.updatetAt = timestamp() \"\n",
    "                        \"RETURN 'relation ' + type(r) + ' created between ' + a.attribute + ' and ' + b.attribute\", \n",
    "                        idx_a=idx_a, idx_b=idx_b, env=env, weight=weight)\n",
    "        \n",
    "        entire_result = []\n",
    "        for record in result:\n",
    "            entire_result.append(record[0])\n",
    "            \n",
    "        return entire_result\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _delete_self_relations(tx, env):\n",
    "        result = tx.run(\"MATCH (a {env: $env})-[rel:IS_SIMILAR_TO]->(a) DELETE rel\", env=env)\n",
    "        \n",
    "        entire_result = []\n",
    "        for record in result:\n",
    "            entire_result.append(record[0])\n",
    "            \n",
    "        return entire_result\n",
    "   \n",
    "    @staticmethod\n",
    "    def _delete_all(tx, env):\n",
    "        result = tx.run(\"MATCH (n {env: $env}) DETACH DELETE n\", env=env)\n",
    "        \n",
    "        entire_result = []\n",
    "        for record in result:\n",
    "            entire_result.append(record[0])\n",
    "            \n",
    "        return entire_result\n",
    "    \n",
    "    @staticmethod\n",
    "    def _fetch_related_tables_by_signature_to_2_grade(tx, dataset, weight, dastart, daend, env):\n",
    "        q = '''\n",
    "            MATCH (a:Table)-[r1:IS_SIMILAR_TO]-(b:Table) \n",
    "            WHERE a.dataset = $dataset AND a.env = $env AND b.env = $env AND r1.weight = $weight\n",
    "                AND $dastart <= r1.updatetAt AND r1.updatetAt <= $daend\n",
    "            OPTIONAL MATCH (b:Table)-[r2:IS_SIMILAR_TO]-(c:Table) \n",
    "            WHERE c.env = $env AND c <> a AND r2.weight = $weight \n",
    "                AND $dastart <= r2.updatetAt AND r2.updatetAt <= $daend\n",
    "            RETURN a, b, c\n",
    "        '''\n",
    "        \n",
    "        result = tx.run(dedent(q), env=env, dataset=dataset, weight=weight, dastart=dastart, daend=daend)\n",
    "\n",
    "        entire_result = []\n",
    "        for record in result:\n",
    "            entire_result.append((record[0], record[1], record[2]))\n",
    "\n",
    "        return entire_result\n",
    "    \n",
    "    @staticmethod\n",
    "    def _fetch_related_tables_by_content_to_1_grade(tx, attribute, weight, dastart, daend, env):\n",
    "        q = '''\n",
    "            MATCH (a:Column)-[r1:IS_ATTRIBUTE_OF]-(b:Table)<-[r2:IS_ATTRIBUTE_OF]-(c:Column)-[r3:IS_SIMILAR_TO]-(d:Column)-[r4:IS_ATTRIBUTE_OF]->(e:Table)\n",
    "            WHERE a.attribute = $attribute AND a.env=$env AND b.env=$env AND c.env=$env AND d.env=$env AND e.env=$env AND b <> e AND r3.weight=$weight\n",
    "                AND $dastart <= r1.updatetAt AND r1.updatetAt <= $daend\n",
    "                AND $dastart <= r2.updatetAt AND r2.updatetAt <= $daend\n",
    "                AND $dastart <= r3.updatetAt AND r3.updatetAt <= $daend\n",
    "                AND $dastart <= r4.updatetAt AND r4.updatetAt <= $daend\n",
    "            RETURN b, c, d, e\n",
    "        '''\n",
    "        \n",
    "        result = tx.run(dedent(q), env=env, attribute=attribute, weight=weight, dastart=dastart, daend=daend)\n",
    "\n",
    "        entire_result = []\n",
    "        for record in result:\n",
    "            entire_result.append((record[0], record[1], record[2], record[3]))\n",
    "\n",
    "        return entire_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af62c126-f551-47d6-a15d-74c9cf704169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"hash\": \"778cf3734337f29c14b27816f0a7b7de\", \"version\": 5}'\n",
      "{'hash': '778cf3734337f29c14b27816f0a7b7de', 'version': 5}\n",
      "adventureworks-for-postgres-person-address\n",
      "b'{\"hash\": \"d3ceff9c1ba2f60621c24fd72bd6629c\", \"version\": 1}'\n",
      "{'hash': 'd3ceff9c1ba2f60621c24fd72bd6629c', 'version': 1}\n",
      "adventureworks-for-postgres-person-addresstype\n",
      "b'{\"hash\": \"e08d5d9a9c77d127c4f6ca62a693bce8\", \"version\": 1}'\n",
      "{'hash': 'e08d5d9a9c77d127c4f6ca62a693bce8', 'version': 1}\n",
      "adventureworks-for-postgres-person-businessentity\n",
      "b'{\"hash\": \"18da5d35d8cc9638ffca9f5328607351\", \"version\": 1}'\n",
      "{'hash': '18da5d35d8cc9638ffca9f5328607351', 'version': 1}\n",
      "adventureworks-for-postgres-person-businessentityaddress\n",
      "b'{\"hash\": \"50b8bf6d8581675def8ba6ef96837c9e\", \"version\": 1}'\n",
      "{'hash': '50b8bf6d8581675def8ba6ef96837c9e', 'version': 1}\n",
      "adventureworks-for-postgres-person-businessentitycontact\n",
      "b'{\"hash\": \"45feb6c7d21b8d4cd11189a75f7df563\", \"version\": 1}'\n",
      "{'hash': '45feb6c7d21b8d4cd11189a75f7df563', 'version': 1}\n",
      "adventureworks-for-postgres-person-contacttype\n",
      "b'{\"hash\": \"45feb6c7d21b8d4cd11189a75f7df563\", \"version\": 1}'\n",
      "{'hash': '45feb6c7d21b8d4cd11189a75f7df563', 'version': 1}\n",
      "adventureworks-for-postgres-person-contacttype\n",
      "b'{\"hash\": \"5dfd0065fae19cd804806c0b84dce347\", \"version\": 1}'\n",
      "{'hash': '5dfd0065fae19cd804806c0b84dce347', 'version': 1}\n",
      "adventureworks-for-postgres-person-countryregion\n",
      "b'{\"hash\": \"26435fc737892b1d3316b9b1dccb5fc7\", \"version\": 1}'\n",
      "{'hash': '26435fc737892b1d3316b9b1dccb5fc7', 'version': 1}\n",
      "adventureworks-for-postgres-person-emailaddress\n",
      "b'{\"hash\": \"d9fa15b1db33d89d8712241999140d5f\", \"version\": 1}'\n",
      "{'hash': 'd9fa15b1db33d89d8712241999140d5f', 'version': 1}\n",
      "adventureworks-for-postgres-person-password\n",
      "b'{\"hash\": \"0b64b48d93f51c8c311d41f7aab526e8\", \"version\": 1}'\n",
      "{'hash': '0b64b48d93f51c8c311d41f7aab526e8', 'version': 1}\n",
      "adventureworks-for-postgres-person-person\n",
      "b'{\"hash\": \"3f20b0690a9d3e6376add512e6629060\", \"version\": 1}'\n",
      "{'hash': '3f20b0690a9d3e6376add512e6629060', 'version': 1}\n",
      "adventureworks-for-postgres-person-personphone\n",
      "b'{\"hash\": \"03ed566a525f0c08f6fbd906dab5dd85\", \"version\": 1}'\n",
      "{'hash': '03ed566a525f0c08f6fbd906dab5dd85', 'version': 1}\n",
      "adventureworks-for-postgres-person-phonenumbertype\n",
      "b'{\"hash\": \"58f4b5c3d82a59e9d7bd1814a3e6c312\", \"version\": 1}'\n",
      "{'hash': '58f4b5c3d82a59e9d7bd1814a3e6c312', 'version': 1}\n",
      "adventureworks-for-postgres-person-stateprovince\n",
      "b'{\"hash\": \"8da284cf055ee14c1db0c44966f7ed7e\", \"version\": 1}'\n",
      "{'hash': '8da284cf055ee14c1db0c44966f7ed7e', 'version': 1}\n",
      "adventureworks-for-postgres-person-vadditionalcontactinfo\n",
      "b'{\"hash\": \"778cf3734337f29c14b27816f0a7b7de\", \"version\": 1}'\n",
      "{'hash': '778cf3734337f29c14b27816f0a7b7de', 'version': 1}\n",
      "adventureworks-for-postgres-person-address_2\n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "\n",
    "env = 'dev'\n",
    "reset_on_restart = False\n",
    "debug = False\n",
    "\n",
    "cache = StrictRedis()\n",
    "es = Elasticsearch()\n",
    "graph = GraphStorage(\"bolt://localhost:7687\", \"neo4j\", \"password\", env, debug)\n",
    "\n",
    "pool = redis.ConnectionPool(host='localhost', port=6379, db=4)\n",
    "version_cache = redis.Redis(connection_pool=pool)\n",
    "\n",
    "index_content = {\n",
    "    'dev': 'dev-havel-index-content',\n",
    "    'test': 'test-havel-index-content',\n",
    "    'prod': 'prod-havel-index-content'\n",
    "}\n",
    "\n",
    "index_signature = {\n",
    "    'dev': 'dev-havel-index-signature',\n",
    "    'test': 'test-havel-index-signature',\n",
    "    'prod': 'prod-havel-index-signature'\n",
    "}\n",
    "\n",
    "es_res_max_size = '10000'\n",
    "\n",
    "if (reset_on_restart):\n",
    "    clear_cache_ns('db0')\n",
    "    clear_cache_ns('db1')\n",
    "    clear_cache_ns('db2')\n",
    "    clear_cache_ns('db3')\n",
    "    \n",
    "    clear_es(env)\n",
    "    create_es_schema_content(env)\n",
    "    create_es_schema_signature(env)\n",
    "    \n",
    "    graph.delete_all()   \n",
    "\n",
    "\n",
    "lsh = {\n",
    "    '0.5':  MinHashLSH(\n",
    "        threshold=0.5, num_perm=128, storage_config={\n",
    "        'type': 'redis',\n",
    "        'basename': bytearray(index_content[env], 'utf-8'),\n",
    "        'redis': {'host': 'localhost', 'port': 6379, 'db': 0}\n",
    "    }),\n",
    "    '0.7': MinHashLSH(\n",
    "        threshold=0.7, num_perm=128, storage_config={\n",
    "        'type': 'redis',\n",
    "        'basename': bytearray(index_content[env], 'utf-8'),\n",
    "        'redis': {'host': 'localhost', 'port': 6379, 'db': 1}\n",
    "    }),\n",
    "    '0.9': MinHashLSH(\n",
    "        threshold=0.9, num_perm=128, storage_config={\n",
    "        'type': 'redis',\n",
    "        'basename': bytearray(index_content[env], 'utf-8'),\n",
    "        'redis': {'host': 'localhost', 'port': 6379, 'db': 2}\n",
    "     })\n",
    "}\n",
    "\n",
    "lsh_sig = {\n",
    "    '0.8': MinHashLSH(\n",
    "        threshold=0.8, num_perm=128, storage_config={\n",
    "        'type': 'redis',\n",
    "        'basename': bytearray(index_content[env], 'utf-8'),\n",
    "        'redis': {'host': 'localhost', 'port': 6379, 'db': 3}\n",
    "     })\n",
    "}\n",
    "\n",
    "\n",
    "# Create Profiles\n",
    "for source, schema, dataset, url, df in config_data: create_profiles_signature(source, schema, dataset, df, env, lsh_sig)\n",
    "for source, schema, dataset, url, df in config_data: create_profiles_content(source, schema, dataset, df, env, lsh)\n",
    "\n",
    "# Create Table nodes\n",
    "nodes, edges = get_nodes_and_edges(env, index_signature[env], lsh_sig)\n",
    "for hit in nodes: graph.insert_table_node(hit['_id'], hit['_source'])\n",
    "for k,b,th in edges:\n",
    "    for v in b: \n",
    "        if debug: print(\"key: %s - bucket: %s - threshold: %s\"%(k, b, th))\n",
    "        graph.add_table_table_relation(k,v,th)\n",
    "\n",
    "# Create Column nodes\n",
    "nodes, edges = get_nodes_and_edges(env, index_content[env], lsh)\n",
    "for hit in nodes: graph.insert_column_node(hit['_id'], calc_idx_signature(hit['_source']), hit['_source'])\n",
    "for k,b,th in edges:\n",
    "    for v in b: \n",
    "        if debug: print(\"key: %s - bucket: %s - threshold: %s\"%(k, b, th))\n",
    "        graph.add_column_column_relation(k,v,th)\n",
    "\n",
    "# Cleanup\n",
    "graph.remove_self_relations()\n",
    "\n",
    "graph.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cc3dfbd-a4ab-4fdb-b922-b9677a516fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1669201932000\n",
      "1669226950274\n",
      "[{'id': 'adventureworks-for-postgres-person-address-addressline1', 'score': 12.170639, 'source': 'adventureworks-for-postgres', 'schema': 'person', 'dataset': 'address', 'attribute': 'addressline1'}, {'id': 'adventureworks-for-postgres-person-address_2-addressline1', 'score': 12.170639, 'source': 'adventureworks-for-postgres', 'schema': 'person', 'dataset': 'address_2', 'attribute': 'addressline1'}]\n",
      "[(<Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:108' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224737572, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 5, 'updatetAt': 1669226230913}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:5' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552856, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 4, 'updatetAt': 1669224620403}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:14' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552938, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address_2', 'dataset': 'address_2', 'version': 1, 'updatetAt': 1669226230995}>), (<Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:108' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224737572, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 5, 'updatetAt': 1669226230913}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:14' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552938, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address_2', 'dataset': 'address_2', 'version': 1, 'updatetAt': 1669226230995}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:5' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552856, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 4, 'updatetAt': 1669224620403}>), (<Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:5' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552856, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 4, 'updatetAt': 1669224620403}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:14' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552938, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address_2', 'dataset': 'address_2', 'version': 1, 'updatetAt': 1669226230995}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:108' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224737572, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 5, 'updatetAt': 1669226230913}>), (<Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:5' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552856, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 4, 'updatetAt': 1669224620403}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:108' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224737572, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 5, 'updatetAt': 1669226230913}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:14' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552938, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address_2', 'dataset': 'address_2', 'version': 1, 'updatetAt': 1669226230995}>)]\n",
      "adventureworks-for-postgres-person-address - \n",
      "adventureworks-for-postgres-person-address - \n",
      "adventureworks-for-postgres-person-address_2\n",
      "\n",
      "adventureworks-for-postgres-person-address - \n",
      "adventureworks-for-postgres-person-address_2 - \n",
      "adventureworks-for-postgres-person-address\n",
      "\n",
      "adventureworks-for-postgres-person-address - \n",
      "adventureworks-for-postgres-person-address_2 - \n",
      "adventureworks-for-postgres-person-address\n",
      "\n",
      "adventureworks-for-postgres-person-address - \n",
      "adventureworks-for-postgres-person-address - \n",
      "adventureworks-for-postgres-person-address_2\n",
      "\n",
      "[(<Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:14' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552938, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address_2', 'dataset': 'address_2', 'version': 1, 'updatetAt': 1669226230995}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:5' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552856, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 4, 'updatetAt': 1669224620403}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:108' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224737572, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 5, 'updatetAt': 1669226230913}>), (<Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:14' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552938, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address_2', 'dataset': 'address_2', 'version': 1, 'updatetAt': 1669226230995}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:108' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224737572, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 5, 'updatetAt': 1669226230913}>, <Node element_id='4:ef40828f-517e-4346-9649-9f38ec1a4def:5' labels=frozenset({'Table'}) properties={'schema': 'person', 'createdAt': 1669224552856, 'source': 'adventureworks-for-postgres', 'env': 'dev', 'idx': 'adventureworks-for-postgres-person-address', 'dataset': 'address', 'version': 4, 'updatetAt': 1669224620403}>)]\n",
      "adventureworks-for-postgres-person-address_2 - \n",
      "adventureworks-for-postgres-person-address - \n",
      "adventureworks-for-postgres-person-address\n",
      "\n",
      "adventureworks-for-postgres-person-address_2 - \n",
      "adventureworks-for-postgres-person-address - \n",
      "adventureworks-for-postgres-person-address\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- address version: 5\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address version: 4 -> (rowguid - rowguid) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (spatiallocation - spatiallocation) <- address version: 5\n",
      "\n",
      "address version: 4 -> (spatiallocation - spatiallocation) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (postalcode - postalcode) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (stateprovinceid - stateprovinceid) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (city - city) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (addressid - addressid) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (addressid - addressid) <- businessentityaddress version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (rowguid - rowguid) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (rowguid - rowguid) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (spatiallocation - spatiallocation) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (spatiallocation - spatiallocation) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (spatiallocation - spatiallocation) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (postalcode - postalcode) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (postalcode - postalcode) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (stateprovinceid - stateprovinceid) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (stateprovinceid - stateprovinceid) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (city - city) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (city - city) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (addressline2 - addressline2) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (addressid - addressid) <- businessentityaddress version: 1\n",
      "\n",
      "address_2 version: 1 -> (addressid - addressid) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (addressid - addressid) <- address version: 4\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address version: 4\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address version: 4\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address version: 5 -> (rowguid - rowguid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (rowguid - rowguid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address version: 4\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address version: 4\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (postalcode - postalcode) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (postalcode - postalcode) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (stateprovinceid - stateprovinceid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (stateprovinceid - stateprovinceid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (city - city) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (city - city) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressline2 - addressline2) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressline2 - addressline2) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressline1 - addressline1) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressline1 - addressline1) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressline1 - addressline1) <- address version: 4\n",
      "\n",
      "address version: 5 -> (addressid - addressid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressid - addressid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressid - addressid) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 5 -> (addressid - addressid) <- businessentityaddress version: 1\n",
      "\n",
      "- - - - - - \n",
      "\n",
      "- - - - - - \n",
      "\n",
      "- - - - - - \n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- address version: 5\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address version: 4 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address version: 4 -> (rowguid - rowguid) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (spatiallocation - spatiallocation) <- address version: 5\n",
      "\n",
      "address version: 4 -> (spatiallocation - spatiallocation) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (postalcode - postalcode) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (stateprovinceid - stateprovinceid) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (city - city) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (addressid - addressid) <- address_2 version: 1\n",
      "\n",
      "address version: 4 -> (addressid - addressid) <- businessentityaddress version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (modifieddate - modifieddate) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (rowguid - rowguid) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (rowguid - rowguid) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (spatiallocation - spatiallocation) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (spatiallocation - spatiallocation) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (spatiallocation - spatiallocation) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (postalcode - postalcode) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (postalcode - postalcode) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (stateprovinceid - stateprovinceid) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (stateprovinceid - stateprovinceid) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (city - city) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (city - city) <- address version: 4\n",
      "\n",
      "address_2 version: 1 -> (addressline2 - addressline2) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (addressid - addressid) <- businessentityaddress version: 1\n",
      "\n",
      "address_2 version: 1 -> (addressid - addressid) <- address version: 5\n",
      "\n",
      "address_2 version: 1 -> (addressid - addressid) <- address version: 4\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address version: 4\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address version: 4\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- password version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- vadditionalcontactinfo version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- personphone version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address version: 5 -> (modifieddate - modifieddate) <- emailaddress version: 1\n",
      "\n",
      "address version: 5 -> (rowguid - rowguid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (rowguid - rowguid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address version: 4\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address version: 4\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (spatiallocation - spatiallocation) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (postalcode - postalcode) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (postalcode - postalcode) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (stateprovinceid - stateprovinceid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (stateprovinceid - stateprovinceid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (city - city) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (city - city) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressline2 - addressline2) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressline2 - addressline2) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressline1 - addressline1) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressline1 - addressline1) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressline1 - addressline1) <- address version: 4\n",
      "\n",
      "address version: 5 -> (addressid - addressid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressid - addressid) <- address_2 version: 1\n",
      "\n",
      "address version: 5 -> (addressid - addressid) <- businessentityaddress version: 1\n",
      "\n",
      "address version: 5 -> (addressid - addressid) <- businessentityaddress version: 1\n",
      "\n",
      "- - - - - - \n",
      "\n",
      "- - - - - - \n",
      "\n",
      "- - - - - - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%local \n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "daend = int(datetime.timestamp(datetime.now())*1000)\n",
    "\n",
    "a = datetime(2022, 11, 23, 12, 12, 12)\n",
    "dastart = int(datetime.timestamp(a)*1000)\n",
    "\n",
    "print(dastart)\n",
    "print(daend)\n",
    "\n",
    "graph = GraphStorage(\"bolt://localhost:7687\", \"neo4j\", \"password\", env, False)\n",
    "es = Elasticsearch()\n",
    "\n",
    "# Eminhizer\n",
    "res = search_dataset_for_topic(index_content[env], \"Firestone Drive\")\n",
    "print(res)\n",
    "\n",
    "# find related datasets\n",
    "\n",
    "for r in res:\n",
    "    related_nodes_by_signature_to_2_grade = graph.find_related_tables_by_signature_to_2_grade(r['dataset'], '0.8', dastart, daend)\n",
    "    \n",
    "    print(related_nodes_by_signature_to_2_grade)\n",
    "    for node in related_nodes_by_signature_to_2_grade: \n",
    "        print(str(node[0]['idx']) + ' - ')\n",
    "        print(str(node[1]['idx']) + ' - ')\n",
    "        print(str(node[2]['idx']) + '\\n')\n",
    "        \n",
    "for r in res:\n",
    "    related_nodes_by_content_to_1_grad = graph.find_related_tables_by_content_to_1_grad(r['attribute'], '0.5', dastart, daend)\n",
    "\n",
    "    for node in related_nodes_by_content_to_1_grad: \n",
    "        print(str(node[0]['dataset']) + ' version: '+ str(node[0]['version']) + ' -> (' + str(node[1]['attribute']) + ' - ' + str(node[2]['attribute']) + ') <- ' + str(node[3]['dataset']) + ' version: '+ str(node[3]['version']) + '\\n')\n",
    "    \n",
    "    print('- - - - - - \\n')\n",
    "    print('- - - - - - \\n')\n",
    "    print('- - - - - - \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2749e8-d721-42e8-ba44-cd4fb8b78229",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local \n",
    "\n",
    "graph = GraphStorage(\"bolt://localhost:7687\", \"neo4j\", \"password\", env, False)\n",
    "es = Elasticsearch()\n",
    "\n",
    "res = search_dataset_for_topic(index_content[env], \"Eminhizer\")\n",
    "\n",
    "# find related datasets\n",
    "\n",
    "related_datasets = {\n",
    "    'related_nodes_by_signature_to_2_grade': [],\n",
    "    'related_nodes_by_content_to_1_grad': []\n",
    "}\n",
    "\n",
    "for r in res:\n",
    "    related_datasets['related_nodes_by_signature_to_2_grade'].append(graph.find_related_tables_by_signature_to_2_grade(r['dataset'], '0.8'))\n",
    "\n",
    "for r in res:\n",
    "    related_datasets['related_nodes_by_content_to_1_grad'].append(graph.find_related_tables_by_content_to_1_grad(r['id'], '0.5'))\n",
    "    \n",
    "\n",
    "for node in related_datasets['related_nodes_by_signature_to_2_grade']:\n",
    "    print(node)\n",
    "    if (node):\n",
    "        print(str(node[0]['name']) + ' - ')\n",
    "        print(str(node[1]['name']) + ' - ')\n",
    "        print(str(node[2]['name']) + '\\n')\\\n",
    "\n",
    "for node in related_datasets['related_nodes_by_content_to_1_grad']:\n",
    "    print(node)\n",
    "    if node:\n",
    "        a = node[0]\n",
    "        print(str(a['name']) + ' -> (' + str(node[1]['name']) + ' - ' + str(node[2]['name']) + ') <- ' + str(node[3]['name']) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86019510-f176-4bcd-9f7e-9aae7a0edd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local \n",
    "\n",
    "arr = np.array([ 42114592,  127266168,  215678469,   17266034,   34121180,  942441018,\n",
    "  227629861,  772424727,  258055101,  289724735,  117062477,  555008702,\n",
    "   29604049,  840321879,  378698042, 1209184744,  243903852,   64306427,\n",
    "  418573613,   50885453,  443551390,  238376316,  629454598,  646390910,\n",
    "  258707738,  287206176,   86790830,  230629753,  353312205,   72417695,\n",
    "  113209494,  247807691,  494356438,  598711389,  163905412,   92705481,\n",
    "  167455200,  120333262,  690658470,  503937613,   13774441,  138757320,\n",
    "  429215096,  166965839,  604024314,  151611451,  482383227,   80185077,\n",
    "  132702729,  637863885,  809374076,   15601261,  231429825,  508796949,\n",
    "   93190304,  246310319,  252884464,   76719615,   27566880,  600163519,\n",
    "    9727857,   11786542,  156050497,  303860790,  228751560,  912519144,\n",
    "    9156249,  369895830,  727826405,  416426394, 1081480011,   66120612,\n",
    "  135376155,  210143265, 1031356013,   90284798, 1016601632,   13573364,\n",
    "   68970483,  161433822,  542646600,   96345609,  685539749,   84541516,\n",
    "   86327512,  187842457,  132296212,  857191589,   20737788,  590826688,\n",
    "  444073826,  192175731,  212992765,  114574843,  171782812,   70248969,\n",
    "  202706043,  702713690,  338155350,  342468131,  542793283,  261167155,\n",
    "  378396244,  211528111,  231333263,  103754312,  129317962,   55448546,\n",
    " 1041271092,  594880347,  931295081,  225781925,   83509603,  776091994,\n",
    "  298124272,  467369673,    8909661,   60688953,  115820188,   54821235,\n",
    "  168100490,   33183095,  712469771,  323850472,  414195156,  550484318,\n",
    "  388634331,   42270916], dtype=np.int64)\n",
    "\n",
    "mt = MinHash(num_perm=128)\n",
    "mt.hashvalues = arr\n",
    "mt.seed = 1\n",
    "\n",
    "lsh['0.7'].query(mt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
